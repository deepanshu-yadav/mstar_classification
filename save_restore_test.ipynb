{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.pre_processing import get_data as g\n",
    "# from src.plotting import plotter as ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_PATH = os.path.join( os.getcwd(),'datasets' ,'SARBake'  )\n",
    "# X , Y, cls_train ,cls_test , labels_train , labels_test, class_names  =g.get_full_dataset(BASE_PATH,200,200,80,20)\n",
    "# print(X.shape)\n",
    "# print(class_names)\n",
    "\n",
    "# images = Y[0,0:9,:,:,:]\n",
    "\n",
    "# # Get the true classes for those images.\n",
    "# cls_true = cls_test[0:9]\n",
    "\n",
    "# # Plot the images and labels using our helper-function above.\n",
    "# ptr.plot_images(images=images, cls_true=cls_true, class_names=class_names ,smooth=False)\n",
    "\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cls_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import numpy as np\n",
    "\n",
    "\n",
    "# idx = np.random.choice(len(labels_train),\n",
    "#                                size = 16,\n",
    "#                                replace=False)\n",
    "\n",
    "\n",
    "# X_dash=X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_dash.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tensor_utilities.models import *\n",
    "from src.tensor_utilities.training import *\n",
    "\n",
    "import os\n",
    "from src.pre_processing import get_data as g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> epoch 600 training data 4000 examples </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tensor_utilities.models import *\n",
    "from src.tensor_utilities.training import *\n",
    "\n",
    "import os\n",
    "from src.pre_processing import get_data as g\n",
    "\n",
    "\n",
    "def build_and_train():\n",
    "    #os.chdir(\"../../\")\n",
    "    img_size = 200\n",
    "    num_channels = 3\n",
    "    no_training = 400\n",
    "    no_test = 100\n",
    "    learning_rate = 0.00001\n",
    "    no_of_epochs = 600\n",
    "\n",
    "    BASE_PATH = os.path.join(os.getcwd(), 'datasets', 'SARBake')\n",
    "    X, Y, cls_train, cls_test, labels_train, labels_test, class_names = g.get_full_dataset(BASE_PATH, img_size, img_size, no_training, no_test)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model = Model()\n",
    "\n",
    "    with model.graph.as_default():\n",
    "        x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "        y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "        y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "        model.getsimpleCNNModel(x, num_classes)\n",
    "\n",
    "        model.getLoss(y_true)\n",
    "\n",
    "        global_step = tf.Variable(initial_value=0,\n",
    "                                  name='global_step', trainable=False)\n",
    "\n",
    "        model.getOptimizer(global_step=global_step, learning_rate=learning_rate)\n",
    "\n",
    "        y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "        y_pred_cls = tf.argmax(model.pred, dimension=1)\n",
    "\n",
    "        correct_prediction = tf.equal(  y_pred_cls , y_true_cls)\n",
    "\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        train = Train(learning_rate=learning_rate, bath_size=32, no_of_epochs=no_of_epochs, graph=model.graph,accuracy=accuracy ,loss=model.loss)\n",
    "\n",
    "        train.optimize(x, y_true, global_step, model.optimizer, accuracy, X, labels_train, if_restore=True)\n",
    "\n",
    "        train.print_test_accuracy(x=x,y_true=y_true,y_pred_cls=y_pred_cls,images_test=Y,labels_test=labels_test,cls_test=cls_test,class_names=class_names,show_confusion_matrix=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> further increasing epochs doesnot improve accuracy  </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:    100, Training Batch Accuracy:  31.2%\n",
      "Global Step:    200, Training Batch Accuracy:  71.9%\n",
      "Global Step:    300, Training Batch Accuracy:  71.9%\n",
      "Global Step:    400, Training Batch Accuracy:  78.1%\n",
      "Global Step:    500, Training Batch Accuracy:  90.6%\n",
      "Global Step:    600, Training Batch Accuracy:  90.6%\n",
      "1000\n",
      "Accuracy on Test-Set: 72.9% (729 / 1000)\n",
      "Confusion Matrix:\n",
      "[94  0  0  0  4  1  0  0  0  1] (0) 2S1\n",
      "[ 3 70  1  2 14  0  0  9  0  1] (1) BMP2\n",
      "[ 0  0 96  0  1  0  1  0  1  1] (2) BRDM2\n",
      "[ 0 14  2 22 10  0  0  2  0 50] (3) BTR60\n",
      "[ 2  6  1  2 15  0  0  2  0 72] (4) BTR70\n",
      "[ 3  0  0  2  0 92  1  0  1  1] (5) D7\n",
      "[12  0  5  0  0  3 68  0 10  2] (6) T62\n",
      "[ 1 11  1  1  1  0  0 84  0  1] (7) T72\n",
      "[ 2  0  1  0  0  3  0  0 93  1] (8) ZIL131\n",
      "[ 1  0  1  0  0  1  1  0  1 95] (9) ZSU23\n",
      "(0)(1)(2)(3)(4)(5)(6)(7)(8)(9)\n"
     ]
    }
   ],
   "source": [
    "build_and_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> increasing training data to 6000 and 1100 epochs</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_validation\n"
     ]
    }
   ],
   "source": [
    "# img_size = 200\n",
    "# num_channels = 3\n",
    "# no_training = 400\n",
    "# no_test = 100\n",
    "# learning_rate = 0.00001\n",
    "# no_of_epochs = 600\n",
    "\n",
    "# num_classes = 10\n",
    "\n",
    "# model = Model()\n",
    "\n",
    "# with model.graph.as_default():\n",
    "#     x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "#     y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "#     y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "#     model.getsimpleCNNModel(x, num_classes)\n",
    "\n",
    "#     model.getLoss(y_true)\n",
    "\n",
    "#     global_step = tf.Variable(initial_value=0,\n",
    "#                                   name='global_step', trainable=False)\n",
    "\n",
    "#     model.getOptimizer(global_step=global_step, learning_rate=learning_rate)\n",
    "\n",
    "#     y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "#     y_pred_cls = tf.argmax(model.pred, dimension=1)\n",
    "\n",
    "#     correct_prediction = tf.equal(  y_pred_cls , y_true_cls)\n",
    "\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "#     train = Train(learning_rate=learning_rate, bath_size=32, no_of_epochs=no_of_epochs, graph=model.graph,accuracy=accuracy ,loss=model.loss)\n",
    "\n",
    "#     train.saver.restore(sess=train.session,save_path=train.save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_restore_train():\n",
    "    #os.chdir(\"../../\")\n",
    "    img_size = 100\n",
    "    num_channels = 3\n",
    "    no_training = 50\n",
    "    no_test = 10\n",
    "    learning_rate = 0.00001\n",
    "    no_of_epochs = 2\n",
    "\n",
    "    BASE_PATH = os.path.join(os.getcwd(), 'datasets', 'SARBake')\n",
    "    X, Y, cls_train, cls_test, labels_train, labels_test, class_names = g.get_datset_in_batch(BASE_PATH, img_size, img_size, no_training, no_test)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model = Model()\n",
    "\n",
    "    with model.graph.as_default():\n",
    "        x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "        y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "        model.getsimpleCNNModel(x, num_classes)\n",
    "\n",
    "        model.getLoss(y_true)\n",
    "\n",
    "        global_step = tf.Variable(initial_value=0,\n",
    "                                  name='global_step', trainable=False)\n",
    "\n",
    "        model.getOptimizer(global_step=global_step, learning_rate=learning_rate)\n",
    "\n",
    "        model.getAccuracy(y_true)\n",
    "       \n",
    "        train = Train(learning_rate=learning_rate, bath_size=80, no_of_epochs=no_of_epochs, graph=model.graph,accuracy=model.accuracy ,loss=model.loss)\n",
    "        \n",
    "        #train.saver.restore(sess=train.session,save_path=train.save_path)\n",
    "        \n",
    "        train.optimize(x, y_true, global_step, model.optimizer, model.accuracy, X, labels_train,Y , labels_test )\n",
    "\n",
    "        train.print_test_accuracy(x=x,y_true=y_true,y_pred_cls=model.class_predicted,images_test=Y,labels_test=labels_test,cls_test=cls_test,class_names=class_names,show_confusion_matrix=True,show_example_errors=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:      2, Training Batch Accuracy:  16.2%\n",
      "100\n",
      "Accuracy on Test-Set: 15.0% (15 / 100)\n",
      "Example errors:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8b71899e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[5 0 1 1 0 0 2 1 0 0] (0) 2S1\n",
      "[4 0 0 0 0 0 5 1 0 0] (1) BMP2\n",
      "[2 0 0 0 0 0 6 2 0 0] (2) BRDM2\n",
      "[2 0 1 1 1 0 3 1 0 1] (3) BTR60\n",
      "[5 0 1 0 0 0 3 1 0 0] (4) BTR70\n",
      "[2 0 1 0 0 0 6 1 0 0] (5) D7\n",
      "[1 0 0 0 0 0 8 1 0 0] (6) T62\n",
      "[5 0 0 2 0 0 2 1 0 0] (7) T72\n",
      "[2 0 1 0 0 0 6 1 0 0] (8) ZIL131\n",
      "[4 0 0 0 0 0 5 1 0 0] (9) ZSU23\n",
      "(0)(1)(2)(3)(4)(5)(6)(7)(8)(9)\n"
     ]
    }
   ],
   "source": [
    "build_restore_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>  image size 100 by 100 9000 training examples and epochs 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
